{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGgxkjNYeJjo"
   },
   "source": [
    "# Part 1 - Setup and Data Preparation\n",
    "In this section, we will:\n",
    "- Import necessary packages for this demonstration\n",
    "- Load the data\n",
    "- Ensure that qualitative predictor variables are of the *category* data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwCptqDKeJj3"
   },
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import 'numpy' and 'pandas' for working with numbers and data frames\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import 'pyplot' from 'matplotlib' and 'seaborn' for visualizations\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import method for regression from 'statsmodels'\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Import method for regression from 'sklearn'\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import 'train_test_split' from 'sklearn' for train-validation-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import 'mean_squared_error' from 'sklearn' for error computations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import method to compute VIFs\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLvFWr-PeJkB"
   },
   "outputs": [],
   "source": [
    "# Data source\n",
    "# link = 'https://archive.ics.uci.edu/dataset/10/automobile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CwN--nveJkE"
   },
   "outputs": [],
   "source": [
    "# Load the data and take a look at it\n",
    "df = pd.read_csv('carprices.csv', index_col = 'car_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPaWIbFHeJkG"
   },
   "outputs": [],
   "source": [
    "# Load the data description and take a look at it\n",
    "dd = pd.read_csv('carpricesdatadescription.csv', index_col = 'feature')\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDf7_Md3eJkL"
   },
   "outputs": [],
   "source": [
    "# Look at the specifics of the data frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P0DqVcxeJkN"
   },
   "source": [
    "Most features in this dataset are numeric, being either of the *int64* datatype or the *float64* datatype, but some features are of the *object* datatype. These are, in fact, strings. Typically, when conducting categorical analysis, it is better to convert these into the *category* datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNYfEFPZeJkP"
   },
   "outputs": [],
   "source": [
    "# Convert qualitative predictors to the 'category' data type\n",
    "categorical_columns = df.select_dtypes(include = 'object').columns\n",
    "df[categorical_columns] = df[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXw3PNxleJkQ"
   },
   "outputs": [],
   "source": [
    "# Look at the specifics of the data frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aZcjG9EeJkR"
   },
   "source": [
    "**Note:** The *object* datatype entries are now of the *category* datatype. This helps in conducting categorical analysis more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmryX8R9eJkW"
   },
   "source": [
    "It is important to note that the *symboling* feature has been recorded as an integer but it is actually a categorical variable. We can understand this from the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3wEBWbmeJkX"
   },
   "outputs": [],
   "source": [
    "# Convert the 'symboling' feature to the 'category' datatype\n",
    "df['symboling'] = df['symboling'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjBB-ajqeJkZ"
   },
   "outputs": [],
   "source": [
    "# Drop the car name as it won't be useful in the overall analysis\n",
    "df.drop(labels = 'carname', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52ubvS6HeJkb"
   },
   "source": [
    "**Note:** Names, identifiers, and so on, are generally not considered as valid predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQuVOsvOeJkd"
   },
   "outputs": [],
   "source": [
    "# Take a look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8baOOHsbeJke"
   },
   "outputs": [],
   "source": [
    "# Check the shape and size of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4V38MBSeJkf"
   },
   "source": [
    "**Note:** This is, of course, a small dataset. For this demonstration, we will use a subset of the features. Learners may explore with the original dataset at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ww9zzChHeJkf"
   },
   "outputs": [],
   "source": [
    "# Retain a select number of columns for the purposes of this demonstration\n",
    "df = df[['symboling',\n",
    "         'carbody',\n",
    "         'enginelocation',\n",
    "         'carlength',\n",
    "         'carwidth',\n",
    "         'carheight',\n",
    "         'curbweight',\n",
    "         'horsepower',\n",
    "         'citympg',\n",
    "         'highwaympg',\n",
    "         'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fm5qne7AeJki"
   },
   "outputs": [],
   "source": [
    "# Take a look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2-YH7p3eJkm"
   },
   "outputs": [],
   "source": [
    "# Check the shape and size of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKePF7BneJko"
   },
   "outputs": [],
   "source": [
    "# Look at the specifics of the data frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WwzxhMEBeJko"
   },
   "outputs": [],
   "source": [
    "# Store the categorical column names\n",
    "categorical_columns = df.select_dtypes(include = 'category').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbv1F5d-eJkp"
   },
   "outputs": [],
   "source": [
    "# Split the data into input and output\n",
    "X = df.drop(labels = 'price', axis = 1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxIXLsbQeJkp"
   },
   "source": [
    "**Note:** The target variable here is the price of the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azcI3VrBeJkp"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets\n",
    "# Note: There's no validation dataset because we are not fine-tuning any of the models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtxmqwdGeJkq"
   },
   "source": [
    "**Note:** Fixing a random state value ensures reproducibility of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zgb-QpNWeJkq"
   },
   "outputs": [],
   "source": [
    "# Check the number of observations in the train and test datasets\n",
    "print('Training dataset size: ', len(X_train))\n",
    "print('Testing dataset size: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPuUFS_rAexT"
   },
   "source": [
    "# Part 2 - Exploratory Data Analysis\n",
    "In this section, we will conduct EDA on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaLY5nWJAexf"
   },
   "outputs": [],
   "source": [
    "# Create count plots for the categorical variables\n",
    "plt.figure(figsize = (8, 3))\n",
    "\n",
    "fignum = 0\n",
    "for featurename in categorical_columns:\n",
    "    fignum = fignum + 1\n",
    "    plt.subplot(1, 3, fignum)\n",
    "    sns.countplot(data = df, x = featurename)\n",
    "    plt.xticks(rotation = 45)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pb7BmX1neJkr"
   },
   "outputs": [],
   "source": [
    "# Drop the engine location feature as there is very high class imbalance\n",
    "df.drop(labels = 'enginelocation', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXo3iqXDeJkr"
   },
   "outputs": [],
   "source": [
    "# Create a pair plot for the numerical features in the data set\n",
    "# sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWFP3-ffeJks"
   },
   "outputs": [],
   "source": [
    "# Look at the correlation matrix for the numerical features in the dataset\n",
    "df.corr().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrGKxM9geJks"
   },
   "source": [
    "**Note:** Correlation values can tell us about redundancies in the dataset. For example, here, there's a very high correlation between the car weight and the car length. So, we can consider dropping on of these features if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3uE2fUceJkt"
   },
   "outputs": [],
   "source": [
    "df_cat = pd.get_dummies(data = df, columns = ['symboling', 'carbody'], drop_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy3MRRASeJkt",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at the correlation matrix for all the features in the dataset\n",
    "df_cat.corr().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wQyVKe2eJku"
   },
   "source": [
    "**Note:** Interpreting correlation matrices with categorical features can be challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4HjzhpBAexj"
   },
   "source": [
    "# Part 3 - Multiple Linear Regression Models\n",
    "In this section, we will train and evaluate linear regression models for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed7hdfejeJku"
   },
   "source": [
    "## Numerical Predictors - *statsmodels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Huj-w8toeJkv"
   },
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqCdrdgYeJk8"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'carlength'\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_1 = smf.ols('price ~ carlength', data = df)\n",
    "lr_model_1 = lr_model_1.fit()\n",
    "print(lr_model_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBst_dI-Aexj"
   },
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mUdCzMwAexj"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'carlength' and 'carwidth'\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_2 = smf.ols('price ~ carlength + carwidth', data = df)\n",
    "lr_model_2 = lr_model_2.fit()\n",
    "print(lr_model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sg9pk6iAeJk9"
   },
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukyIhqA6eJk9"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'carlength', 'carwidth' and 'carheight'\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_3 = smf.ols('price ~ carlength + carwidth + carheight', data = df)\n",
    "lr_model_3 = lr_model_3.fit()\n",
    "print(lr_model_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7LkBE7neJk9"
   },
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ugqq03OReJk-"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using all the numerical predictors\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_4 = smf.ols('price ~ carlength + carwidth + carheight + curbweight + horsepower + citympg + highwaympg', data = df)\n",
    "lr_model_4 = lr_model_4.fit()\n",
    "print(lr_model_4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgfoMa1ceJk-"
   },
   "source": [
    "**Note:** In general practice, we may begin by fitting a linear regression model using all the input features and then assessing which features are helpful and which are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tYwpey3eJk_"
   },
   "source": [
    "The *carlength*, *carweight*, *citympg* and *highwaympg* features seem to be statistically insignificant. Let us keep this in mind as we go forward with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eg4Jew4NeJk_"
   },
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r91fcm3ceJk_"
   },
   "outputs": [],
   "source": [
    "# Look at the correlation matrix for the numerical features in the dataset\n",
    "df.corr().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X93zP8nieJlA"
   },
   "outputs": [],
   "source": [
    "# Retain correlation values greater than or equal to 0.6\n",
    "df.corr().round(2)[abs(df.corr()) >= 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHmQogC6eJlA"
   },
   "source": [
    "We can try to choose combinations of features that are not correlated strongly with each other but are somewhat correlated with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8beXqpgceJlB"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using all the numerical predictors except 'highwaympg' and 'carlength'\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_5 = smf.ols('price ~ carwidth + carheight + curbweight + horsepower + citympg', data = df)\n",
    "lr_model_5 = lr_model_5.fit()\n",
    "print(lr_model_5.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10Ys3_tneJlC"
   },
   "source": [
    "The *carheight* feature seems to be statistically insignificant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CI4n-4ZeJlC"
   },
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-wTK-0zeJlD"
   },
   "outputs": [],
   "source": [
    "# Retain correlation values greater than or equal to 0.6\n",
    "df.corr().round(2)[abs(df.corr()) >= 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgYJrNt6eJlG"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using all the numerical predictors except 'highwaympg', 'carlength' and 'carheight'\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_6 = smf.ols('price ~ carwidth + curbweight + horsepower + citympg', data = df)\n",
    "lr_model_6 = lr_model_6.fit()\n",
    "print(lr_model_6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhGA1nwzeJlI"
   },
   "source": [
    "Adjusted R-squared seems to have increased without any change to R-squared. This is a good thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHEf9ASYeJlK"
   },
   "source": [
    "### Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1M1ZUSN_eJlL"
   },
   "outputs": [],
   "source": [
    "# Retain correlation values greater than or equal to 0.6\n",
    "df.corr().round(2)[abs(df.corr()) >= 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHVJ8GyreJlM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'curbweight', 'horsepower' and 'citympg'\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_7 = smf.ols('price ~ curbweight + horsepower + citympg', data = df)\n",
    "lr_model_7 = lr_model_7.fit()\n",
    "print(lr_model_7.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yeNz2mseJlf"
   },
   "source": [
    "This looks like a decent model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj1AEs_ZeJlf"
   },
   "source": [
    "### Model 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwO-yFEIeJlg"
   },
   "source": [
    "### Numerical Predictors - VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOJs3MoveJlg"
   },
   "outputs": [],
   "source": [
    "# Obtain the VIFs for the numerical features in the dataset\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "numerical_columns = ['carlength', 'carwidth', 'carheight', 'curbweight', 'horsepower', 'citympg', 'highwaympg']\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = numerical_columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(df[numerical_columns].values, i) for i in range(len(df[numerical_columns].columns))]\n",
    "vif_data.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiC7Sh-eeJlh"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'curbweight' and 'horsepower'\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_8 = smf.ols('price ~ curbweight + horsepower', data = df)\n",
    "lr_model_8 = lr_model_8.fit()\n",
    "print(lr_model_8.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ2F8fU8eJlh"
   },
   "source": [
    "This model has decent R-squared and no statistically insignificant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLx9ToxFeJli"
   },
   "source": [
    "**Note:** When creating and observing linear regression models for the purpose of analysis of predictor impact on target variable, we may choose to use the complete dataset, but when building ML models for the purpose of deployment, only the training data is used for analytical and model-building tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qy0ok0XfeJli"
   },
   "source": [
    "## Numerical Predictors - *sklearn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5q2fVpqeJlj"
   },
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljCufiQFeJlj"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'carlength'\n",
    "# Note: Using only the training data\n",
    "lr_model_1 = LinearRegression()\n",
    "lr_model_1 = lr_model_1.fit(X_train[['carlength']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEDq-gnneJlk"
   },
   "outputs": [],
   "source": [
    "# Look at the intercept and coefficient values\n",
    "print('Intercept: ', lr_model_1.intercept_)\n",
    "print('Coefficient: ', lr_model_1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-Kn5k1heJll"
   },
   "outputs": [],
   "source": [
    "# Obtain predictions on the testing set\n",
    "lr_model_1.predict(X_test[['carlength']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZADmajJWeJll"
   },
   "outputs": [],
   "source": [
    "# Look at the general predictive performance of the model\n",
    "pd.DataFrame(index = X_test.index,\n",
    "             data = {'Truths': y_test,\n",
    "                     'Predictions': lr_model_1.predict(X_test[['carlength']])}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9RYjfxZeJln"
   },
   "outputs": [],
   "source": [
    "# Summarize the performance of the model on the test data using RMSE and MAPE\n",
    "y_pred_lr_list = lr_model_1.predict(X_test[['carlength']])\n",
    "rmse = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_lr_list))\n",
    "mape = np.mean(np.abs(y_test - y_pred_lr_list) / y_test) * 100\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "mape = np.round(mape, 2)\n",
    "\n",
    "performance_df = pd.DataFrame(index = [0],\n",
    "                              data = {'Model': 'SLR model 1', 'RMSE': rmse, 'MAPE': mape})\n",
    "\n",
    "performance_df.set_index(keys = 'Model', inplace = True)\n",
    "\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TV9lDYgeJlo"
   },
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTpyxvabeJlo"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'carlength' and 'carwidth'\n",
    "# Note: Using only the training data\n",
    "lr_model_2 = LinearRegression()\n",
    "lr_model_2 = lr_model_2.fit(X_train[['carlength', 'carwidth']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTH2VGJLeJlp"
   },
   "outputs": [],
   "source": [
    "# Look at the intercept and coefficient values\n",
    "print('Intercept: ', lr_model_2.intercept_)\n",
    "print('Coefficient: ', lr_model_2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbVlk-4yeJlq"
   },
   "outputs": [],
   "source": [
    "# Obtain predictions on the testing set\n",
    "lr_model_2.predict(X_test[['carlength', 'carwidth']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGGR_cLQeJlr"
   },
   "outputs": [],
   "source": [
    "# Look at the general predictive performance of the model\n",
    "pd.DataFrame(index = X_test.index,\n",
    "             data = {'Truths': y_test,\n",
    "                     'Predictions': lr_model_2.predict(X_test[['carlength', 'carwidth']])}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPrHowHheJlr"
   },
   "outputs": [],
   "source": [
    "# Summarize the performance of the model on the test data using RMSE and MAPE\n",
    "y_pred_lr_list = lr_model_2.predict(X_test[['carlength', 'carwidth']])\n",
    "rmse = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_lr_list))\n",
    "mape = np.mean(np.abs(y_test - y_pred_lr_list) / y_test) * 100\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "mape = np.round(mape, 2)\n",
    "\n",
    "performance_df_temp = pd.DataFrame(index = [0],\n",
    "                                   data = {'Model': 'MLR model 2', 'RMSE': rmse, 'MAPE': mape})\n",
    "\n",
    "performance_df_temp.set_index(keys = 'Model', inplace = True)\n",
    "\n",
    "performance_df = pd.concat(objs = [performance_df, performance_df_temp])\n",
    "\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqHGCh8xeJls"
   },
   "source": [
    "### Models 1 through 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ChD_ndueJlt"
   },
   "outputs": [],
   "source": [
    "# Store a list of the model names\n",
    "model_names = []\n",
    "model_names.append('SLR model 1')\n",
    "for i in np.arange(2, 9, 1):\n",
    "    model_names.append('MLR model ' + str(i))\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEyfxlmyeJlu"
   },
   "outputs": [],
   "source": [
    "# Store the different combinations of input features of the models in a list\n",
    "model_inputs = [['carlength'],\n",
    "                ['carlength', 'carwidth'],\n",
    "                ['carlength', 'carwidth', 'carheight'],\n",
    "                numerical_columns,\n",
    "                ['carwidth', 'carheight', 'curbweight', 'horsepower', 'citympg'],\n",
    "                ['carwidth', 'curbweight', 'horsepower', 'citympg'],\n",
    "                ['curbweight', 'horsepower', 'citympg'],\n",
    "                ['curbweight', 'horsepower']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oW00Hx89eJlu"
   },
   "outputs": [],
   "source": [
    "# Create a data frame to store the names of these models and their predictive performance values\n",
    "performance_df = pd.DataFrame(index = model_names, data = {'RMSE': None, 'MAPE': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqAHT_FxeJlu"
   },
   "outputs": [],
   "source": [
    "# Loop through these models by training, evaluating and storing the predictive performance values\n",
    "i = -1\n",
    "for model_input in model_inputs:\n",
    "    i = i + 1\n",
    "    temp_lr_model = LinearRegression()\n",
    "    temp_lr_model = temp_lr_model.fit(X_train[model_input], y_train)\n",
    "    y_pred_lr_list = temp_lr_model.predict(X_test[model_input])\n",
    "    rmse = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_lr_list))\n",
    "    mape = np.mean(np.abs(y_test - y_pred_lr_list) / y_test) * 100\n",
    "    performance_df.loc[model_names[i], 'RMSE'] = np.round(rmse, 2)\n",
    "    performance_df.loc[model_names[i], 'MAPE'] = np.round(mape, 2)\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlGiZ41CeJlv"
   },
   "source": [
    "It seems that the model that uses *curbweight*, *horsepower* and *citympg* to predict the price of the car is doing well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWL4XM2WeJlv"
   },
   "source": [
    "## Numerical and Categorical Predictors - *statsmodels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jpi3nfYveJlw"
   },
   "source": [
    "### Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFZDmt7yeJlw"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using all the numerical predictors and the 'carbody' predictor\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_9 = smf.ols('price ~ carlength + carwidth + carheight + curbweight + horsepower + citympg + highwaympg + carbody', data = df)\n",
    "lr_model_9 = lr_model_9.fit()\n",
    "print(lr_model_9.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbZqybHgeJlw"
   },
   "source": [
    "### Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WkphPR4eJlw"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using all the predictors\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "lr_model_10 = smf.ols('price ~ carlength + carwidth + carheight + curbweight + horsepower + citympg + highwaympg + carbody + symboling', data = df)\n",
    "lr_model_10 = lr_model_10.fit()\n",
    "print(lr_model_10.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l_zBLC_eJlx"
   },
   "source": [
    "**Note:** Though the same rules of interpretation may be applied in these cases as well, it may be challenging to understand the impact of categorical features in the predictive power of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM72BwF4eJlx"
   },
   "source": [
    "## Numerical and Categorical Predictors - *sklearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovpu3kDIeJlx"
   },
   "outputs": [],
   "source": [
    "# Obtain dummy variables for the categorical features in both the training and testing input data\n",
    "X_train_dummies = pd.get_dummies(data = X_train, columns = ['carbody', 'symboling'], drop_first = True)\n",
    "X_test_dummies = pd.get_dummies(data = X_test, columns = ['carbody', 'symboling'], drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnJEkQbaeJly"
   },
   "source": [
    "### Model 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5m-JRp-eJly"
   },
   "outputs": [],
   "source": [
    "# Look at the correlation matrix for all the features in the dataset\n",
    "df_cat.corr().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxsMPnx5eJly",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retain correlation values greater than or equal to 0.6\n",
    "df_cat.corr().round(2)[abs(df_cat.corr()) >= 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz1Cqe9aeJlz"
   },
   "source": [
    "**Note:** The problem with categorical features and correlation values is that categorical variables have binary values for each level. The interpretability of the correlation coefficient in this case can be questioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_olfi-9aeJlz"
   },
   "source": [
    "### Numerical and Categorical Predictors - VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvgdMmIreJlz"
   },
   "outputs": [],
   "source": [
    "# Obtain the VIFs for all the features in the dataset\n",
    "# Note: Using all the data for analytical purposes but when building models generally only training data is used\n",
    "df_dummies = pd.get_dummies(data = df, columns = ['carbody', 'symboling'], drop_first = True)\n",
    "all_columns = df_dummies.drop('price', axis = 1).columns\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = all_columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(df_dummies[all_columns].values, i) for i in range(len(df_dummies[all_columns].columns))]\n",
    "vif_data.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ewzTPbveJl0"
   },
   "source": [
    "**Note:** The categorical variables are interfering with the VIF values of the numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osyqxI5deJl0"
   },
   "outputs": [],
   "source": [
    "# View the features with VIFs less than 50\n",
    "vif_data[vif_data['VIF'] < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TL7iBUG6eJl0"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using all the features with apparently low VIFs\n",
    "# Note: Using only the training data\n",
    "lr_model_11 = LinearRegression()\n",
    "lr_model_11 = lr_model_11.fit(X_train_dummies[vif_data[vif_data['VIF'] < 50]['feature'].values], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lks8F_3EeJl1"
   },
   "outputs": [],
   "source": [
    "# Look at the predictive performance of this model\n",
    "y_pred_lr_list = lr_model_11.predict(X_test_dummies[vif_data[vif_data['VIF'] < 50]['feature'].values])\n",
    "rmse = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_lr_list))\n",
    "mape = np.mean(np.abs(y_test - y_pred_lr_list) / y_test) * 100\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "mape = np.round(mape, 2)\n",
    "\n",
    "print('RMSE = ', rmse)\n",
    "print('MAPE = ', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbU7LfTmeJl1"
   },
   "source": [
    "### Model 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0YPI4L5eJl2"
   },
   "outputs": [],
   "source": [
    "# Retain correlation values greater than or equal to 0.6\n",
    "df_cat.corr().round(2)[abs(df_cat.corr()) >= 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFcadVCieJl5"
   },
   "outputs": [],
   "source": [
    "# Look at the summary output of the analytical model with all the predictors\n",
    "print(lr_model_10.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAH35vI-eJl6"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'curbweight', 'horsepower', 'citympg', 'carbody' and 'symboling'\n",
    "# Note: Using only the training data\n",
    "lr_model_12 = LinearRegression()\n",
    "lr_model_12 = lr_model_12.fit(X_train_dummies[['curbweight', 'horsepower', 'citympg', 'carbody_hardtop', 'carbody_hatchback', 'carbody_sedan', 'carbody_wagon', 'symboling_-1', 'symboling_0', 'symboling_1', 'symboling_2', 'symboling_3']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYGh9smueJl7"
   },
   "outputs": [],
   "source": [
    "# Look at the predictive performance of this model\n",
    "y_pred_lr_list = lr_model_12.predict(X_test_dummies[['curbweight', 'horsepower', 'citympg', 'carbody_hardtop', 'carbody_hatchback', 'carbody_sedan', 'carbody_wagon', 'symboling_-1', 'symboling_0', 'symboling_1', 'symboling_2', 'symboling_3']])\n",
    "rmse = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_lr_list))\n",
    "mape = np.mean(np.abs(y_test - y_pred_lr_list) / y_test) * 100\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "mape = np.round(mape, 2)\n",
    "\n",
    "print('RMSE = ', rmse)\n",
    "print('MAPE = ', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeFNwSW5eJl8"
   },
   "source": [
    "### Model 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfyiPBf-eJl8"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'curbweight', 'horsepower', 'citympg' and 'symboling'\n",
    "# Note: Using only the training data\n",
    "lr_model_13 = LinearRegression()\n",
    "lr_model_13 = lr_model_13.fit(X_train_dummies[['curbweight', 'horsepower', 'citympg', 'symboling_-1', 'symboling_0', 'symboling_1', 'symboling_2', 'symboling_3']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2y-xu8KHeJl9"
   },
   "outputs": [],
   "source": [
    "# Look at the predictive performance of this model\n",
    "y_pred_lr_list = lr_model_13.predict(X_test_dummies[['curbweight', 'horsepower', 'citympg', 'symboling_-1', 'symboling_0', 'symboling_1', 'symboling_2', 'symboling_3']])\n",
    "rmse = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_lr_list))\n",
    "mape = np.mean(np.abs(y_test - y_pred_lr_list) / y_test) * 100\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "mape = np.round(mape, 2)\n",
    "\n",
    "print('RMSE = ', rmse)\n",
    "print('MAPE = ', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBk6fam-eJl-"
   },
   "source": [
    "### Model 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMpA5yYreJl-"
   },
   "outputs": [],
   "source": [
    "# Create and train a linear regression model for the data and view its summary\n",
    "# Note: The objective is to predict 'price' using 'curbweight', 'horsepower', and 'symboling'\n",
    "# Note: Using only the training data\n",
    "lr_model_14 = LinearRegression()\n",
    "lr_model_14 = lr_model_14.fit(X_train_dummies[['curbweight', 'horsepower', 'symboling_-1', 'symboling_0', 'symboling_1', 'symboling_2', 'symboling_3']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mh4VTjgxeJl-"
   },
   "outputs": [],
   "source": [
    "# Look at the predictive performance of this model\n",
    "y_pred_lr_list = lr_model_14.predict(X_test_dummies[['curbweight', 'horsepower', 'symboling_-1', 'symboling_0', 'symboling_1', 'symboling_2', 'symboling_3']])\n",
    "rmse = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_lr_list))\n",
    "mape = np.mean(np.abs(y_test - y_pred_lr_list) / y_test) * 100\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "mape = np.round(mape, 2)\n",
    "\n",
    "print('RMSE = ', rmse)\n",
    "print('MAPE = ', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDSPBweoeJl_"
   },
   "source": [
    "It seems as though the model that uses *curbweight*, *horsepower*, *citympg*, *carbody* and *symboling* is doing well on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWLsbZGeeJmA"
   },
   "outputs": [],
   "source": [
    "temp_model = LinearRegression()\n",
    "temp_model = temp_model.fit(X_train_dummies[['curbweight', 'horsepower', 'citympg', 'carbody_hardtop', 'carbody_hatchback', 'carbody_sedan', 'carbody_wagon']], y_train)\n",
    "y_pred_lr_list = temp_model.predict(X_test_dummies[['curbweight', 'horsepower', 'citympg', 'carbody_hardtop', 'carbody_hatchback', 'carbody_sedan', 'carbody_wagon']])\n",
    "rmse = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_lr_list))\n",
    "mape = np.mean(np.abs(y_test - y_pred_lr_list) / y_test) * 100\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "mape = np.round(mape, 2)\n",
    "\n",
    "print('RMSE = ', rmse)\n",
    "print('MAPE = ', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFHSizSKeJmA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
